{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NASA asteroid classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KATE expects your code to define variables with specific names that correspond to certain things we are interested in.\n",
    "\n",
    "KATE will run your notebook from top to bottom and check the latest value of those variables, so make sure you don't overwrite them.\n",
    "\n",
    "* Remember to uncomment the line assigning the variable to your answer and don't change the variable or function names.\n",
    "* Use copies of the original or previous DataFrames to make sure you do not overwrite them by mistake.\n",
    "\n",
    "You will find instructions below about how to define each variable.\n",
    "\n",
    "Once you're happy with your code, upload your notebook to KATE to check your feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will a train Decision Tree Classifier to predict if some Near to Earth objects (NEO) constitute an hazard for planet Earth. The dataset is a pre-processed version of the original dataset that comes from a NASA [website](https://data.nasa.gov/Space-Science/Asteroids-NeoWs-API/73uw-d9i8), and that you can also find following this [link](https://www.kaggle.com/shrutimehta/nasa-asteroids-classification).\n",
    "\n",
    "For the preprocessing, some columns have been deleted either because they were redundant, because they were of no use for solving the classification problem, or because they were too correlated with the output variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/00/h4l_zl594z1g4kp3qw9d3bdc0000gn/T/ipykernel_56376/1220206431.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "np.random.seed(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset and variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Load the dataset called `nasa_asteroids.csv` into a DataFrame**\n",
    "\n",
    "Store the answer in a variable called `df`and call the `.head()` method to view the first 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Est Dia in KM(min)</th>\n",
       "      <th>Est Dia in KM(max)</th>\n",
       "      <th>Relative Velocity km per sec</th>\n",
       "      <th>Relative Velocity km per hr</th>\n",
       "      <th>Miles per hour</th>\n",
       "      <th>Orbit Uncertainity</th>\n",
       "      <th>Jupiter Tisserand Invariant</th>\n",
       "      <th>Epoch Osculation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>Semi Major Axis</th>\n",
       "      <th>Inclination</th>\n",
       "      <th>Asc Node Longitude</th>\n",
       "      <th>Orbital Period</th>\n",
       "      <th>Perihelion Distance</th>\n",
       "      <th>Perihelion Arg</th>\n",
       "      <th>Aphelion Dist</th>\n",
       "      <th>Mean Anomaly</th>\n",
       "      <th>Mean Motion</th>\n",
       "      <th>Hazardous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.127220</td>\n",
       "      <td>0.284472</td>\n",
       "      <td>6.115834</td>\n",
       "      <td>22017.003799</td>\n",
       "      <td>13680.509944</td>\n",
       "      <td>5</td>\n",
       "      <td>4.634</td>\n",
       "      <td>2458000.5</td>\n",
       "      <td>0.425549</td>\n",
       "      <td>1.407011</td>\n",
       "      <td>6.025981</td>\n",
       "      <td>314.373913</td>\n",
       "      <td>609.599786</td>\n",
       "      <td>0.808259</td>\n",
       "      <td>57.257470</td>\n",
       "      <td>2.005764</td>\n",
       "      <td>264.837533</td>\n",
       "      <td>0.590551</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.146068</td>\n",
       "      <td>0.326618</td>\n",
       "      <td>18.113985</td>\n",
       "      <td>65210.346095</td>\n",
       "      <td>40519.173105</td>\n",
       "      <td>3</td>\n",
       "      <td>5.457</td>\n",
       "      <td>2458000.5</td>\n",
       "      <td>0.351674</td>\n",
       "      <td>1.107776</td>\n",
       "      <td>28.412996</td>\n",
       "      <td>136.717242</td>\n",
       "      <td>425.869294</td>\n",
       "      <td>0.718200</td>\n",
       "      <td>313.091975</td>\n",
       "      <td>1.497352</td>\n",
       "      <td>173.741112</td>\n",
       "      <td>0.845330</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.231502</td>\n",
       "      <td>0.517654</td>\n",
       "      <td>7.590711</td>\n",
       "      <td>27326.560182</td>\n",
       "      <td>16979.661798</td>\n",
       "      <td>0</td>\n",
       "      <td>4.557</td>\n",
       "      <td>2458000.5</td>\n",
       "      <td>0.348248</td>\n",
       "      <td>1.458824</td>\n",
       "      <td>4.237961</td>\n",
       "      <td>259.475979</td>\n",
       "      <td>643.580228</td>\n",
       "      <td>0.950791</td>\n",
       "      <td>248.415038</td>\n",
       "      <td>1.966857</td>\n",
       "      <td>292.893654</td>\n",
       "      <td>0.559371</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008801</td>\n",
       "      <td>0.019681</td>\n",
       "      <td>11.173874</td>\n",
       "      <td>40225.948191</td>\n",
       "      <td>24994.839864</td>\n",
       "      <td>6</td>\n",
       "      <td>5.093</td>\n",
       "      <td>2458000.5</td>\n",
       "      <td>0.216578</td>\n",
       "      <td>1.255903</td>\n",
       "      <td>7.905894</td>\n",
       "      <td>57.173266</td>\n",
       "      <td>514.082140</td>\n",
       "      <td>0.983902</td>\n",
       "      <td>18.707701</td>\n",
       "      <td>1.527904</td>\n",
       "      <td>68.741007</td>\n",
       "      <td>0.700277</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.127220</td>\n",
       "      <td>0.284472</td>\n",
       "      <td>9.840831</td>\n",
       "      <td>35426.991794</td>\n",
       "      <td>22012.954985</td>\n",
       "      <td>1</td>\n",
       "      <td>5.154</td>\n",
       "      <td>2458000.5</td>\n",
       "      <td>0.210448</td>\n",
       "      <td>1.225615</td>\n",
       "      <td>16.793382</td>\n",
       "      <td>84.629307</td>\n",
       "      <td>495.597821</td>\n",
       "      <td>0.967687</td>\n",
       "      <td>158.263596</td>\n",
       "      <td>1.483543</td>\n",
       "      <td>135.142133</td>\n",
       "      <td>0.726395</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Est Dia in KM(min)  Est Dia in KM(max)  Relative Velocity km per sec  \\\n",
       "0            0.127220            0.284472                      6.115834   \n",
       "1            0.146068            0.326618                     18.113985   \n",
       "2            0.231502            0.517654                      7.590711   \n",
       "3            0.008801            0.019681                     11.173874   \n",
       "4            0.127220            0.284472                      9.840831   \n",
       "\n",
       "   Relative Velocity km per hr  Miles per hour  Orbit Uncertainity  \\\n",
       "0                 22017.003799    13680.509944                   5   \n",
       "1                 65210.346095    40519.173105                   3   \n",
       "2                 27326.560182    16979.661798                   0   \n",
       "3                 40225.948191    24994.839864                   6   \n",
       "4                 35426.991794    22012.954985                   1   \n",
       "\n",
       "   Jupiter Tisserand Invariant  Epoch Osculation  Eccentricity  \\\n",
       "0                        4.634         2458000.5      0.425549   \n",
       "1                        5.457         2458000.5      0.351674   \n",
       "2                        4.557         2458000.5      0.348248   \n",
       "3                        5.093         2458000.5      0.216578   \n",
       "4                        5.154         2458000.5      0.210448   \n",
       "\n",
       "   Semi Major Axis  Inclination  Asc Node Longitude  Orbital Period  \\\n",
       "0         1.407011     6.025981          314.373913      609.599786   \n",
       "1         1.107776    28.412996          136.717242      425.869294   \n",
       "2         1.458824     4.237961          259.475979      643.580228   \n",
       "3         1.255903     7.905894           57.173266      514.082140   \n",
       "4         1.225615    16.793382           84.629307      495.597821   \n",
       "\n",
       "   Perihelion Distance  Perihelion Arg  Aphelion Dist  Mean Anomaly  \\\n",
       "0             0.808259       57.257470       2.005764    264.837533   \n",
       "1             0.718200      313.091975       1.497352    173.741112   \n",
       "2             0.950791      248.415038       1.966857    292.893654   \n",
       "3             0.983902       18.707701       1.527904     68.741007   \n",
       "4             0.967687      158.263596       1.483543    135.142133   \n",
       "\n",
       "   Mean Motion  Hazardous  \n",
       "0     0.590551       True  \n",
       "1     0.845330      False  \n",
       "2     0.559371       True  \n",
       "3     0.700277      False  \n",
       "4     0.726395       True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add your code below\n",
    "# df = ...\n",
    "\n",
    "df = pd.read_csv('data/nasa_asteroids.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4687 entries, 0 to 4686\n",
      "Data columns (total 19 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Est Dia in KM(min)            4687 non-null   float64\n",
      " 1   Est Dia in KM(max)            4687 non-null   float64\n",
      " 2   Relative Velocity km per sec  4687 non-null   float64\n",
      " 3   Relative Velocity km per hr   4687 non-null   float64\n",
      " 4   Miles per hour                4687 non-null   float64\n",
      " 5   Orbit Uncertainity            4687 non-null   int64  \n",
      " 6   Jupiter Tisserand Invariant   4687 non-null   float64\n",
      " 7   Epoch Osculation              4687 non-null   float64\n",
      " 8   Eccentricity                  4687 non-null   float64\n",
      " 9   Semi Major Axis               4687 non-null   float64\n",
      " 10  Inclination                   4687 non-null   float64\n",
      " 11  Asc Node Longitude            4687 non-null   float64\n",
      " 12  Orbital Period                4687 non-null   float64\n",
      " 13  Perihelion Distance           4687 non-null   float64\n",
      " 14  Perihelion Arg                4687 non-null   float64\n",
      " 15  Aphelion Dist                 4687 non-null   float64\n",
      " 16  Mean Anomaly                  4687 non-null   float64\n",
      " 17  Mean Motion                   4687 non-null   float64\n",
      " 18  Hazardous                     4687 non-null   bool   \n",
      "dtypes: bool(1), float64(17), int64(1)\n",
      "memory usage: 663.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the first few rows we can see that all the columns are numerical except for the output variable we want to predict, the `Hazardous` column, whose values are boolean True / False. We will convert it to a numerical format later in the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a table with the description of the features. Our goal is to use all the available information regarding the asteroids to predict whether or not each is hazardous.\n",
    "\n",
    "| Feature name                 | Description                                                                                                             |\n",
    "|------------------------------|-------------------------------------------------------------------------------------------------------------------------|\n",
    "| Est Dia in KM(min)           | estimate of the minimum diameter of the asteroid in kilometres (KM)                                                     |\n",
    "| Est Dia in KM(max)           | estimate of the maximum diameter of the asteroid in kilometres (KM)                                                     |                                                           |\n",
    "| Relative Velocity km per sec | relative velocity of the asteroid in kilometres per second                                                               |\n",
    "| Relative Velocity km per hr  | relative velocity of the asteroid in kilometres per hour.                                                                |\n",
    "| Miles per hour               | relative velocity of the asteroid in Miles per hour                                                                     |\n",
    "| Orbit Uncertainity           | parameter that indicates the uncertainity on the identification of the orbit                                            |\n",
    "| Jupiter Tisserand Invariant  | Tisserand’s parameter for the asteroid. This parameter is used to distinguish different kinds of orbits                 |\n",
    "| Epoch Osculation             | the instant of time at which the position and velocity vectors are specified                                            |\n",
    "| Eccentricity                 | eccentricity of the asteroid’s orbit, i.e. how far from circular each orbit is                                          |\n",
    "| Semi Major Axis              | Semi Major Axis of the asteroid’s orbit                                                                                 |\n",
    "| Inclination                  | inclination of the asteroid's orbit                                                                                     |\n",
    "| Asc Node Longitude           | angular position at which the asteroid passes from the southern side of the orbital plane of Earth to the northern side |\n",
    "| Orbital Period               | time the asteroid takes to complete one orbit                                                                           |\n",
    "| Perihelion Distance          | Perihelion distance of the asteroid. For a body orbiting the Sun, the point of least distance is the perihelion         |\n",
    "| Perihelion Arg               | angle (starting from the center of the orbit) between the asteroid's periapsis and its ascending node                   |\n",
    "| Aphelion Dist                | the point in the orbit of the asteroid which it is farthest from the sun.                                               |\n",
    "| Mean Anomaly                 | fraction of an elliptical orbit's period that has elapsed since the asteroid passed periapsis                           |\n",
    "| Mean Motion                  | angular speed required for a body to complete one orbit                                                                 |\n",
    "| Hazardous                    | whether the asteroid is hazardous or not                                                                                |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Create a variable where you store the numpy array with the values of all the columns of `df` except for `Hazardous`**\n",
    "\n",
    "Call this variable `X`\n",
    "\n",
    "*Hint: to transform a DataFrame into a numpy array you can use the `.to_numpy()` method.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add your code below\n",
    "# X = ...\n",
    "X = df.iloc[:, :-1].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Create a variable `y` where you store the array with the values of `Hazardous`, where the values `True` are converted to `1` and the values `False` are converted to `0`.**\n",
    "\n",
    "*Hint: Converting a boolean array `arr` with values True/False to an array with values 1/0 is as easy as multiplying `arr` by 1!*\n",
    "\n",
    "Your answer should be a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code below\n",
    "# y = ...\n",
    "y = df['Hazardous'].astype(int).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. What is the fraction of the element of `y` with label 0? Store this number in the variable `frac0`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8389161510561126"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add your code below\n",
    "# frac0 = ...\n",
    "frac0 = np.mean(y==0)\n",
    "frac0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. What is the fraction of the element of `y` with label 1? Store this number in the variable `frac1`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16108384894388736"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add your code below\n",
    "# frac1 = ...\n",
    "frac1 = np.mean(y==1)\n",
    "frac1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is unbalanced. Our tree will have to give more weight on our minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Split the data into training and test sets using sklearn `train_test_split` and specifying `random_state`=8. Also, remember to set the argument `stratify` = y, and set the `test_size` equal to 0.25**\n",
    "\n",
    "Save the result in the variables `x_train`, `x_test`, `y_train`, `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code below\n",
    "# x_train, x_test, y_train, y_test = ...\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25, random_state=8)\n",
    "\n",
    "\n",
    "# test_size=0.25 specifies that 25% of the data should be allocated to the test set.\n",
    "# random_state=8 ensures that your data is split in a reproducible way if you run this code multiple times.\n",
    "# stratify=y ensures that the proportion of labels in your train and test sets reflects the proportion in the original dataset y, \n",
    "# which is particularly important for classification tasks to prevent introducing bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Create a decision tree classifier, with `max_depth=5`, `min_samples_split=3`, `min_samples_leaf=5`, `class_weight=\"balanced\"`, and `random_state=101`**\n",
    "\n",
    "The `random_state` is for reproducibility.\n",
    "\n",
    "Store the tree in a variable called `dec_tree`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code below\n",
    "# dec_tree = ...\n",
    "dec_tree = DecisionTreeClassifier(\n",
    "    max_depth=5,\n",
    "    min_samples_split=3,\n",
    "    min_samples_leaf=5,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=101\n",
    ")\n",
    "\n",
    "# max_depth=5 sets the maximum depth of the tree. Deeper trees can capture more complex patterns but might lead to overfitting.\n",
    "# min_samples_split=3 requires at least 3 samples to split a node. This helps control the size of the tree and prevents overfitting.\n",
    "# min_samples_leaf=5 requires a leaf node to have at least 5 samples. This parameter further helps in smoothing the model, especially in regression.\n",
    "# class_weight=\"balanced\" adjusts weights inversely proportional to class frequencies in the input data. This is useful for handling imbalanced datasets.\n",
    "# random_state=101 ensures reproducibility of your results by setting a seed for the random number generator used in the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Fit the model on `x_train` and `y_train` and compute the accuracy on the training set. Use the `accuracy_score` method from sklearn.metrics.**\n",
    "\n",
    "Store the accuracy in a variable called `acc_train`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7914651493598862"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add your code below\n",
    "# acc_train = ...\n",
    "dec_tree.fit(x_train, y_train)\n",
    "acc_train = dec_tree.score(x_train, y_train)\n",
    "acc_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. What is the accuracy on the test set?**\n",
    "\n",
    "Store your answer in a variable called `acc_test`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7815699658703071"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add your code below\n",
    "# acc_test = ...\n",
    "acc_test = dec_tree.score(x_test, y_test)\n",
    "acc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Create a variable `class_report` where you store the classification report on the test set obtained with the `classification_report` method from sklearn.metrics.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code below\n",
    "# class_report = ...\n",
    "y_test_pred = dec_tree.predict(x_test)\n",
    "class_report = classification_report(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the cell below to have a nicer view of the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.74      0.85       983\n",
      "           1       0.42      0.97      0.59       189\n",
      "\n",
      "    accuracy                           0.78      1172\n",
      "   macro avg       0.71      0.86      0.72      1172\n",
      "weighted avg       0.90      0.78      0.81      1172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's now do a Grid Search to find better hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Define a dictionary with the values of the parameters we want to try in the grid search. \n",
    "Namely, for `max_depth` we will try the values 3, 5, 12; for `min_samples_split` 3, 8, 16; for `min_samples_leaf` 1, 5, 10. \n",
    "\n",
    "Store the dictionary in a variable called `grid_param`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code below\n",
    "# grid_param = ...\n",
    "grid_param = {\n",
    "    'max_depth': [3, 5, 12],\n",
    "    'min_samples_split': [3, 8, 16],\n",
    "    'min_samples_leaf': [1, 5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**12. Define a GridSearch object, where you set `cv=5`. Make sure you use the `dec_tree` variable created earlier.**\n",
    "\n",
    "Store it in a variable called `grid_cv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code below\n",
    "# grid_cv = ...\n",
    "grid_cv = GridSearchCV(estimator=dec_tree, param_grid=grid_param, cv=5)\n",
    "\n",
    "# cv=5 sets the number of cross-validation folds to 5, \n",
    "# meaning the training data will be split into 5 parts, \n",
    "# with 4 parts used for training and 1 part used for validation in each fold, \n",
    "# rotating until each part has been used for validation once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**13. Fit grid_cv on the training set and store the best parameters found with the Grid Search in a variable called `best_parameters`.**\n",
    "\n",
    "Use the method `best_params_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code below\n",
    "# best_parameters = ...\n",
    "grid_cv.fit(x_train, y_train)\n",
    "best_parameters = grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**14. Create a copy of `dec_tree` and store it in a variable called `dec_tree_best`; set its parameters to `best_parameters`. Now train the model on the training set. What is the accuracy on the training set? \n",
    "Store your answer in a variable called `acc_train_best`.**\n",
    "\n",
    "*Hint: to create a copy of your tree, use the `sklearn.base.clone` method. Here is an example of its use: new_tree = sklearn.base.clone(old_tree)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9197724039829303"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add your code below\n",
    "# acc_train_best = ...\n",
    "dec_tree_best = sklearn.base.clone(dec_tree)\n",
    "\n",
    "dec_tree_best.set_params(**best_parameters)\n",
    "# The ** syntax in Python is used to unpack dictionaries into keyword arguments when calling a function or a method. \n",
    "\n",
    "dec_tree_best.fit(x_train, y_train)\n",
    "acc_train_best = dec_tree_best.score(x_train, y_train)\n",
    "acc_train_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**15. What is the accuracy on the test set?**\n",
    "\n",
    "Store your answer in a variable called `acc_test_best`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8950511945392492"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add your code below\n",
    "# acc_test_best = ...\n",
    "acc_test_best = dec_tree_best.score(x_test, y_test)\n",
    "acc_test_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**16. Create a variable `class_report_best` where you store the classification report on the test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code below\n",
    "# class_report_best = ...\n",
    "y_test_pred_best = dec_tree_best.predict(x_test)\n",
    "class_report_best = classification_report(y_test, y_test_pred_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and run the cell below to have a nicer view of the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93       983\n",
      "           1       0.62      0.90      0.73       189\n",
      "\n",
      "    accuracy                           0.90      1172\n",
      "   macro avg       0.80      0.90      0.83      1172\n",
      "weighted avg       0.92      0.90      0.90      1172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, dec_tree_best.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Original Model Metrics**\n",
    "- Accuracy: 0.78\n",
    "- Precision for Class 1: 0.42\n",
    "- Recall for Class 1: 0.97\n",
    "- F1-Score for Class 1: 0.59\n",
    "- Weighted Avg Precision: 0.90\n",
    "- Weighted Avg Recall: 0.78\n",
    "- Weighted Avg F1-Score: 0.81\n",
    "\n",
    "\n",
    "**New/Optimized Model Metrics**\n",
    "- Accuracy: 0.90\n",
    "- Precision for Class 1: 0.62\n",
    "- Recall for Class 1: 0.90\n",
    "- F1-Score for Class 1: 0.73\n",
    "- Weighted Avg Precision: 0.92\n",
    "- - Weighted Avg Recall: 0.90\n",
    "- Weighted Avg F1-Score: 0.90\n",
    "\n",
    "\n",
    "**Comparison and Analysis**\n",
    "- Accuracy: Improved from 0.78 to 0.90, indicating a higher overall rate of correct predictions.\n",
    "- Precision for Class 1: Increased from 0.42 to 0.62, showing that the new model has a better rate of correctly predicting positive instances among all instances predicted as positive.\n",
    "- Recall for Class 1: Decreased slightly from 0.97 to 0.90, but this reduction is offset by the significant gain in precision, leading to more balanced and reliable positive predictions.\n",
    "- F1-Score for Class 1: Increased from 0.59 to 0.73, demonstrating a better balance between precision and recall for the minority class.\n",
    "- Weighted Averages: All weighted metrics (precision, recall, F1-score) have improved, indicating enhanced performance across both classes, taking class imbalance into account.\n",
    "\n",
    "\n",
    "**Conclusion**\n",
    "The optimized model is indeed better than the original model across almost all metrics, showing particularly strong improvements in accuracy, precision, and the weighted average F1-score. This indicates that the grid search effectively identified parameter values that produce a more balanced and accurate model, especially in terms of handling the positive class (Class 1), which often is more challenging in imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
